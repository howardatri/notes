## intro
搜索的应用领域?
info retrieval(IR)信息检索系统:
- 网页检索
- chatbots/ qa 
- 图像搜索引擎

核心功能:检索
目标:**确定用户发出的查询与待检索内容之间的相关性**
==本综述仅关注文本检索系统(通过匹配得分来衡量查询与文档的相关性)==

提升检索性能: 1查询重构(上游) 2重排序和读取(下游)

reranking:仅针对检索器已检索到的有限数量的相关文档，所以重点在于高性能而非高效

检索->重排序->集成阅读组件，总结检索文档(提供给用户简洁文档)
*区分:传统的ir通常需要用户自行收集和整理相关信息*


fig1：llms 1用于增强传统信息检索组件(查询重写器，检索器，重排序器，阅读器) 2 用于搜索代理来执行multiple 信息检索任务


lr发展历程 **平衡传统优势与现代神经网络架构的过程** :
基于词项(term-based) ->统计语言模型(BM25算法-考虑词频和文档长度变化)->神经模型(善于捕捉semantic nuances 和复杂上下文线索)==挑战:数据稀缺、可解释性、不准确但合理的响应==

利用llm无疑可以提高ir性能

llm被证明在ir特定模块(如检索器)中非常有用


**综述深入探讨了 LLM 与信息检索系统之间的交集，涵盖了查询重写器、检索器、重排序器和阅读器等关键视角**
还收录了一些利用llm作为搜索代理来执行任务的研究

更侧重于开发和应用LLM于IR系统的技术和方法。此外，我们建议阅读中国IR界的战略报告，该报告探讨了LLM时代IR的机遇和未来发展方向，我们认为它是对本综述的极佳补充。

其余部分组织:2ir与llm背景 3456从查询重写器等四个检索组件回顾最新发展 7 搜索代理新发展 8 未来潜在方向 9 总结主要发现

## 2 background
boolean model: 用布尔逻辑运算符来组合查询
vector space model:基于词袋，把文档和查询变成向量(倒排索引提升)
statics model: 估计词项出现的可能性(可观的上下文感知能力)
neural: 利用强大表达能力(学习函数模式潜在关系)，捕捉q与d的语义关系

已发现的挑战:query ambiguity(歧义)  , retrieval efficiency

注意力集中于检索过程的关键模块上(q re-writer,retriever, re-ranker, reading component)
### 2.1 ir
#### query re-writer
usage && task:提升查询精确度和表达力(expressiveness)

integral part: **query expansion techniques(查询扩展技术(伪相关反馈prominent))**

应用: 除了提升通用搜索效率，还有个性化搜索和对话式搜索

#### retriever(粗)
usage&&task: document recall(文档召回)
goal:高召回率

经典模型BM25 多年来 展示了稳健性能和高效率

recent:神经ir范式兴起，主流围绕**将 查询 于 文档投影到高维向量空间，然后通过计算内积来计算相关度得分**
	why? 更有效理解q与d关系，利用向量表示的强大功能捕捉语义相似性

#### re-ranker(细)
usage&&task: fine-grained(细粒度) reordering of documents within the retrieved.
goal:高准确率
与强调效率和效果平衡的检索器不同，重排序器模块更注重文档排序的质量。

研究人员**探索了比传统向量内积更复杂的匹配方法**，从而为重排序器提供更丰富的匹配信号。
*支持专门的排序策略*

#### reader
usage&&task: 阅读和理解检索到的文档，并从中提取或生成准确答案

传统:呈现候选文档列表
优势:以更直观的方式组织答案文本，模拟人类获取信息的自然方式

techniques :  **将参考文献整合到生成的响应**中一直是阅读器模块的一项有效技术

### 2.2 llms


基于大规模语料库的biLSTM->(掩码建模/下一句预测)transformer->
**先预训练再微调**范式，比如GPT系列模型/BERT

研究界把大型plm称为大型语言模型

*缩放定律(规模增大性能替身)*  
*涌现能力(当参数规模到达一定阈值后。会突然出现在小模型中不明显的解决复杂任务的能力)*

现状:
	参数规模庞大，针对如信息检索的特定任务。对llm进行微调不可能。  **how?**
	1 ==in-content learning(ICL，上下文学习)==->不仅是预训练资料，而是理解输入上下文       **无需参数调优，ir最常用**
			-仅需自然语言编写任务描述和示例(jigsaw based on qwen)
			-思路链prompting 引导模型推理过程
	2 参数高效微调 
		保持性能的情况下，减少可训练参数的数量(LoRA)。最新进展:QLoRA(reduce memory usage by lever-aging利用 a frozen 4-bit quantized LLM for gradient computation)
		**信息检索任务中的应用有限**❌->潜在研究发现✔️

最近研究改进推理(reasoning)和推理时间(inference time)

LRMs(large reasoning models) 是llm的演进，专门用于处理复杂的逻辑任务，采用reinforcement learning ，设计是为了生成详细的思考过程。对改进推理过程的关注与**测试时扩展(test-time scaling，一种在推理期分配额外计算资源，不增加预训练模型规模情况下提升模型性能)** 高度相关。
-LRMs为信息检索提供新范式

Fig. 2. 基于逻辑推理模型 (LLM) 的即席搜索查询重写示例。该示例引自 Query2Doc 论文。LLM 用于生成一段文字来补充原始查询，其中 N = 0 和 N > 0 分别对应于零样本和少样本场景


下面是重点部分，需要具体了解当前进展
## 3 query re-writer
优化初始查询-查询扩展/重构 
- 基于ad-hoc retrieval(即席搜索-类似数据库检索，一次性，旨在弥合用户查询与潜在文档之间的语义鸿沟)
- 基于对话式搜索(多轮，根据历史上下文来重写当前查询)
传统方法缺陷: 知识模型能力不足&粗略匹配产生的噪声信号
### 3.1 rewriting scenarios


## 4 retriever

## 5 re-ranker


## 6 reader(reading component)

## 7 search agent

## 8 future direction

## 9 conclusion
