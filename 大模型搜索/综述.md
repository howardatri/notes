## intro
搜索的应用领域?
info retrieval(IR)信息检索系统:
- 网页检索
- chatbots/ qa 
- 图像搜索引擎

核心功能:检索
目标:**确定用户发出的查询与待检索内容之间的相关性**
==本综述仅关注文本检索系统(通过匹配得分来衡量查询与文档的相关性)==

提升检索性能: 1查询重构(上游) 2重排序和读取(下游)

reranking:仅针对检索器已检索到的有限数量的相关文档，所以重点在于高性能而非高效

检索->重排序->集成阅读组件，总结检索文档(提供给用户简洁文档)
*区分:传统的ir通常需要用户自行收集和整理相关信息*


fig1：llms 1用于增强传统信息检索组件(查询重写器，检索器，重排序器，阅读器) 2 用于搜索代理来执行multiple 信息检索任务


lr发展历程 **平衡传统优势与现代神经网络架构的过程** :
基于词项(term-based) ->统计语言模型(BM25算法-考虑词频和文档长度变化)->神经模型(善于捕捉semantic nuances 和复杂上下文线索)==挑战:数据稀缺、可解释性、不准确但合理的响应==

利用llm无疑可以提高ir性能

llm被证明在ir特定模块(如检索器)中非常有用


**综述深入探讨了 LLM 与信息检索系统之间的交集，涵盖了查询重写器、检索器、重排序器和阅读器等关键视角**
还收录了一些利用llm作为搜索代理来执行任务的研究

更侧重于开发和应用LLM于IR系统的技术和方法。此外，我们建议阅读中国IR界的战略报告，该报告探讨了LLM时代IR的机遇和未来发展方向，我们认为它是对本综述的极佳补充。

其余部分组织:2ir与llm背景 3456从查询重写器等四个检索组件回顾最新发展 7 搜索代理新发展 8 未来潜在方向 9 总结主要发现

## 2 background
boolean model: 用布尔逻辑运算符来组合查询
vector space model:基于词袋，把文档和查询变成向量(倒排索引提升)
statics model: 估计词项出现的可能性(可观的上下文感知能力)
neural: 利用强大表达能力(学习函数模式潜在关系)，捕捉q与d的语义关系

已发现的挑战:query ambiguity(歧义)  , retrieval efficiency

注意力集中于检索过程的关键模块上(q re-writer,retriever, re-ranker, reading component)
### 2.1 ir
#### query re-writer
usage && task:提升查询精确度和表达力(expressiveness)

integral part: **query expansion techniques(查询扩展技术(伪相关反馈prominent))**

应用: 除了提升通用搜索效率，还有个性化搜索和对话式搜索

#### retriever(粗)
usage&&task: document recall(文档召回)
goal:高召回率

经典模型BM25 多年来 展示了稳健性能和高效率

recent:神经ir范式兴起，主流围绕**将 查询 于 文档投影到高维向量空间，然后通过计算内积来计算相关度得分**
	why? 更有效理解q与d关系，利用向量表示的强大功能捕捉语义相似性

#### re-ranker(细)
usage&&task: fine-grained(细粒度) reordering of documents within the retrieved.
goal:高准确率
与强调效率和效果平衡的检索器不同，重排序器模块更注重文档排序的质量。

研究人员**探索了比传统向量内积更复杂的匹配方法**，从而为重排序器提供更丰富的匹配信号。
*支持专门的排序策略*

#### reader
usage&&task: 阅读和理解检索到的文档，并从中提取或生成准确答案

传统:呈现候选文档列表
优势:以更直观的方式组织答案文本，模拟人类获取信息的自然方式

techniques :  **将参考文献整合到生成的响应**中一直是阅读器模块的一项有效技术

### 2.2 llms


基于大规模语料库的biLSTM->(掩码建模/下一句预测)transformer->
**先预训练再微调**范式，比如GPT系列模型/BERT

研究界把大型plm称为大型语言模型

*缩放定律(规模增大性能替身)*  
*涌现能力(当参数规模到达一定阈值后。会突然出现在小模型中不明显的解决复杂任务的能力)*

现状:
	参数规模庞大，针对如信息检索的特定任务。对llm进行微调不可能。  **how?**
	1 ==in-content learning(ICL，上下文学习)==->不仅是预训练资料，而是理解输入上下文       **无需参数调优，ir最常用**
			-仅需自然语言编写任务描述和示例(jigsaw based on qwen)
			-思路链prompting 引导模型推理过程
	2 参数高效微调 
		保持性能的情况下，减少可训练参数的数量(LoRA)。最新进展:QLoRA(reduce memory usage by lever-aging利用 a frozen 4-bit quantized LLM for gradient computation)
		**信息检索任务中的应用有限**❌->潜在研究发现✔️

最近研究改进推理(reasoning)和推理时间(inference time)

LRMs(large reasoning models) 是llm的演进，专门用于处理复杂的逻辑任务，采用reinforcement learning ，设计是为了生成详细的思考过程。对改进推理过程的关注与**测试时扩展(test-time scaling，一种在推理期分配额外计算资源，不增加预训练模型规模情况下提升模型性能)** 高度相关。
-LRMs为信息检索提供新范式

Fig. 2. 基于逻辑推理模型 (LLM) 的即席搜索查询重写示例。该示例引自 Query2Doc 论文。LLM 用于生成一段文字来补充原始查询，其中 N = 0 和 N > 0 分别对应于零样本和少样本场景


下面是重点部分，需要具体了解当前进展
## 3 query re-writer
优化初始查询-查询扩展/重构 
- 基于ad-hoc retrieval(即席搜索-类似数据库检索，一次性，旨在弥合用户查询与潜在文档之间的语义鸿沟)
- 基于对话式搜索(多轮，根据历史上下文来重写当前查询)
传统方法缺陷: 知识模型能力不足&粗略匹配产生的噪声信号
### 3.1 rewriting scenarios
共指消解问题:

智能体领域有效识别最相关工具成为瓶颈，下面这个提出在工具索引阶段生成一组多样化的合成查询，全面覆盖每个工具文档查询空间的不同方面
“Re-invoke: Tool invocation rewriting for zero-shot tool retrieval,” in Findings of the Association for Computational Linguistics: EMNLP 2024 

llm用于分解和重构复杂的诊断术语(规范化) 并通过“检索和排序”框架改进到标准术语的映射，从而提升整体性能
“Rrnorm: A novel framework for chinese disease diagnoses normalization via llm-driven terminology component recognition and reconstruction,”  ACL2024
### 3.2 Formats of Rewritten Queries
会根据下游问题而变化，整体分为questions,keywords,answer-incorporated passages;
#### 3.2.1questions
将原始查询重写为类似形式的问题是查询重写的自然思路

“Can generative llms create query variants for test collections? an exploratory study,”证明llm生成查询变体潜力--虽然这些变体无法涵盖所有​​人工生成的查询
#### 3.2.2 Keywords
对查询中概念的高级抽象

- BEQUE将新查询构建为关键词[ Large Language Model based Long-tail Query Rewriting in Taobao Search]
- 两轮查询重写过程[Can Query Expansion Improve Generalization of Strong Cross-Encoder Rankers?]首先生成一组高质量种子关键词，然后利用这些关键词增强查询
#### 3.2.3 answer-incorporated passages
==short queries and long documents之间的语义鸿沟一直是挑战==
llm引入新方法：利用给定查询生成的全面答案去语料库(retrieve relenvant passages) 检索相关片段

此机制的通用提示结构:
"给定一个问题查询及其可能的答案段落，编写一个段落来回答该问题 "
	“Knowledge refinement via interaction between search engines and large language models---CoRR 2023
	Retrieval-augmented retrieval: Large language models are strong zero-shot retriever---ACL2024
### 3.3 approaches
methodologies:
	1 prompting 2 supervised fine-tuning 3 RL
	第二个方法查询重写的训练数据匮乏常常是一个挑战->RL


TABLE 2. Examples of different prompting methods in query rewriter.

#### 3.3.1 prompting
zero-shot prompting, few-shot prompting, and chain-of-thought (CoT) prompting(cot是一种涉及迭代提示的策略)

最近的研究[76]探索了八种不同的提示，例如提示LLM 生成查询扩展词而不是完整的伪文档以及 CoT 提示。
query2Doc最有效(↑table 2)
#### 3.3.2 supervised fine-tuning(SFT)
虽然提示方法有效，但LLM并非天然为查询重写任务而设计。为了进一步优化LLM以适应此任务，监督式微调（SFT）应运而生，成为一种很有前景的方法。该方法的一个关键方面是创建合适的训练数据集

在ad-hoc查询，获取数据集是挑战
为了解决这个问题，研究人员通常采用隐式反馈和强化学习来训练查询重写器(implicit feedback)

#### 3.3.3 RL 
查询重写器通常作为检索系统的中介，因此，它们缺乏专门的或独立的损失函数来进行优化。在这种情况下，强化学习 (RL) 提供了一种替代的训练范式。查询重写器可以接收来自下游组件的反馈信号，例如排名模型 [88 “Rafe: Ranking feedback improves query rewriting for RAG] 或 LLM 阅读器 [80 Query rewriting for retrieval-augmented large language models]。
Ma 等人 [80] 提出从 LLM 生成答案，然后将 QA 评估的结果用作训练信号。另一种方法是 BEQUE [81]，它引入了一个离线反馈系统，该系统根据检索到的产品集为每个查询分配一个质量分数。
参照deepseek r1。，使用检索指标作为奖励来优化查询生成器


### 3.4 limitations
- concept drifts 概念飘逸
  llm知识太广，重写时引入不相关的信息->>需要平衡原始核心与利用llm功能来增强和澄清查询
- correlation between retrieval performance and expansion effect
这里主要讲的负相关性，查询扩展对弱模型有益，但是可能损害强模型的性能

## 4 retriever 
第一道文档过滤器，负责收集与用户查询广泛相关的文档
first rule : ==efficiency==    &&  high recall( = retrieved/total)

*神经网络检索器成功因素:数据和模型*

长期存在挑战: 1 用户查询简短含义模糊，难以理解准确意图 2 文档通常包含冗长的内容以及大量噪声 -----数据标注费时费力
现有(以前)主要基于BERT，存在固有局限
llms 角色 ：
### 4.1 leveraging llms to generate search data 
目前主要有两种方式提高llm检索性能:
1 数据精炼方法(侧重重新构建输入查询->精确呈现用户意图)->3
2 训练数据增强方法(利用生成模型来扩充密集检索模型训练数据，尤其是zero/few shot场景)
#### 4.1.2 data augmentation 
- **伪查询生成 (Pseudo query generation)**：给定一个文档，让 LLM 生成可能搜到这个文档的查询 。==成本高==
	- To tackle this, UDAPDR [115] is proposed 它首先使用
LLM为目标域生成有限数量的合成查询。这些高质量的示例随后被用作提示，引导一个较小的模型生成大量查询，从而构建该特定领域的训练集。
    
- **相关性标签生成 (Relevance label generation)**：利用 LLM 估算“给定文档生成该查询”的概率，以此作为“软”的相关性标签 。
    
- **完整样本生成 (Complete example generation)**：让 LLM 直接生成 `(查询, 正样本, 负样本)` 格式的三元组训练数据 。
	- 本文提出了一种两阶段生成流程，其中第一阶段引导语言学习模型（LLM）集思广益，提出各种检索任务，然后第二阶段生成相应的“（查询，正例文档，负例文档）”三元组，以构建合成训练数据。

### 4.2 leveraging llms as retriever's backbone
LLM 直接作为检索模型的核心组件。

- **密集检索器 (Dense Retriever)**：
    
    - **提升现有能力**：使用 LLM 作为文本编码器（Embedder）。研究表明，模型规模和嵌入维度越大，性能越好，泛化能力也越强 。
        
    - **引入新能力**：LLM 带来了 **指令跟随** (Instruction Following) 和 **上下文学习** (In-context Learning) 的能力。
        
- **生成式检索器 (Generative Retriever)**：
    
    - 这是一个颠覆性的范式，**完全抛弃了传统的“索引-检索-排序”** 。
        
    - 它将文档知识存储在模型参数中，在检索时**直接生成文档的唯一标识符 (DocIDs)** 。
        
    - **实现方式**：
        
        - **微调 LLM**：例如 DSI 微调 T5 模型，输入查询，解码出 DocID 。
            
        - **Prompting LLM**：发现 LLM（如 GPT-3）在少样本提示下能直接生成相关网页的 URL 。
### 4.3 limitations
- **延迟 (Latency)**：LLM 参数量巨大，推理时间过长，这对于需要快速响应的检索器是致命的 。
    
- **数据不匹配**：LLM 生成的数据（如伪查询）可能与真实用户查询存在偏差 。
    
- **微调成本**：高效微调这些巨型模型是一个关键问题 。

## 5 re-ranker


## 6 reader(reading component)

## 7 search agent

## 8 future direction

## 9 conclusion
