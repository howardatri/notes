编码器和解码器、编码器-解码器注意力
#### 7.1序列到序列模型
序列到序列模型输入和输出都是一个序列，输入与输出序列长度之间的关系有两种情况。 第一种情况下，输入跟输出的长度一样；第二种情况下，机器决定输出的长度。
##### 7.1.1语音识别，机器翻译与语音翻译
语音识别：输入是声音信号，输出是语音识别的结果
机器翻译：机器输入一个语言的句子，输出另外一个语言的句子
语音翻译：我们对机器说一句话，比如“machine learning”，机器直接把听到的英语的声 音信号翻译成中文
##### 7.1.2语音合成
输入文字、输出声音信号就是语音合成（Text-To-Speech，TTS）。
##### 7.1.3聊天机器人
聊天机器人就是我们对它说一句话，它要给出一个回应。
##### 7.1.4 问答任务
序列到序列模型在自然语言处理的领域的应用很广泛，而很多自然语言处理的任务都可 以想成是问答（Question Answering，QA）的任务.
**问答就是给机器读一段文字，问机器一个问题，希望它可以给出一个正确的答案**
因此各式各样的自然语言处理的问题往往都可以看作是问答的问题，而问答的问题可以 用序列到序列模型来解。
注意：序列到序列模型就像瑞士刀，瑞士刀可以解决各式各样的问题，砍 柴可以用瑞士刀，切菜也可以用瑞士刀，但是它不一定是最好用的。因此针对各种不同的任务 定制的模型往往比只用序列到序列模型的模型更好。
##### 7.1.5句法分析
在句法分析的任务中，输入是一段文字，输出是一个树状的结构，而一个树状的结构可以 看成一个序列，该序列代表了这个树的结构
##### 7.1.6 多标签分类
**多分类问题（multi-class classification）是指分类的类别数大于 2。而多标签分类是指 同一个东西可以属于多个类。**
#### 7.2 Transformer结构
一般的序列到序列模型会分成编码器和解码器，编码器负责处理输入的 序列，再把处理好的结果“丢”给解码器，由解码器决定要输出的序列。
#### 7.3 Transformer 编码器
编码器输入一排向量，输出另外一排 向量。自注意力、循环神经网络、卷积神经网络都能输入一排向量，输出一排向量。Transformer 的编码器使用的是自注意力，输入一排向量，输出另外一个同样长度的向量。

编码器里面会分成很多的块（block），每一个块都是输入一排向量，输 出一排向量。输入一排向量到第一个块，第一个块输出另外一排向量，以此类推，最后一个块 会输出最终的向量序列。

Transformer 的编码器的每个块并不是神经网络的一层，每个块的结构如图7.11所示，在 每个块里面，输入一排向量后做自注意力，考虑整个序列的信息，输出另外一排向量。接下来 这排向量会“丢”到全连接网络网络里面，输出另外一排向量，这一排向量就是块的输出，事实 上在原来的Transformer 里面做的事情是更复杂的。
![[Pasted image 20251012102115.png]]
Transformer 里面加入了**残差连接（residual connection）** 的设计，如图 7.12 所示，最 左边的向量b输入到自注意力层后得到向量a，输出向量a加上其输入向量b得到新的输 出。得到残差的结果以后，再做层归一化（layer normalization）。
*这边用的是残差神经网络的思想。为的是防止梯度消失，使神经网络可以加深。具体可以看ResNet的那篇文章。*
层归一化比批量归一化更简单，不需要考虑批量的信息，而批量归一化需要考虑批量的信息。层归一化输入一个向量，输 出另外一个向量。层归一化会计算输入向量的平均值和标准差。
批量归一化是对不同样本不同特征的同一个维度去计算均值跟标准差，但层归一化是对 同一个特征、同一个样本里面不同的维度去计算均值跟标准差，接着做个归一化。

得到层归一化的输出以后，该输出才是全连接网络的输入。输入到全连接网络，还有一个残差连接，把全连接网络的输入跟它的输出加起来得到新的输出。接着把残差的结果再做 一次层归一化得到的输出才是Transformer 编码器里面一个块的输出。

Q: 为什么Transformer 中使用层归一化，而不使用批量归一化？ A: 论文“PowerNorm: Rethinking Batch Normalization in Transformers”解释了在 Transformers 里面批量归一化不如层归一化的原因，并提出能量归一化（power nor malization）。能量归一化跟层归一化性能差不多，甚至好一点。
![[Pasted image 20251012102907.png]]
Transformer 的编码器其实不一定要这样设计，永远可以思考看看有没有更好的设计方式

#### 7.4 Transformer 解码器
接下来介绍解码器，解码器比较常见的称为自回归的（auto regressive）解码器。
##### 7.4.1 自回归解码器
以语音识别为例，输入一段声音，输出一串文字。
解码器把编码 器的输出先“读”进去。要让解码器产生输出，首先要先给它一个代表开始的特殊符号， 即Begin Of Sequence，这是一个特殊的词元（token）。在词表（vocabulary）里面，在本来解码器可能产生的文字里面多加一个特殊的符号。每一个词元都可以用一个独热的向量来表示。
接下来解码器会“吐” 出一个向量，该向量的长度跟词表的大小是一样的。在产生这个向量之前，跟做分类一样，通 常会先进行一个softmax 操作。这个向量里面的分数是一个分布，该向量里面的值全部加起 来，总和是1。这个向量会给每一个中文字一个分，分数最高的中文字就是最终的输出。“机” 的分数最高，所以“机”就当做是解码器的第一个输出。
接下来把“机”当成解码器新的输入。根据两个输入：特殊符号 和“机”，解码器输出一个蓝色的向量。蓝色的向量里面会给出每一个中文字的分数，假设“器” 的分数最高，“器”就是输出。解码器接下来会拿“器”当作输入，其看到了、“机”、“器”， 可能就输出“学”。解码器看到、“机”、“器”、“学”，它会输出一个向量。这个向量里面“习” 的分数最高的，所以它就输出“习”。这个过程就反复地持续下去。
![[Pasted image 20251012105416.png]]
	解码器的输入是它在前一个时间点的输出，其会把自己的输出当做接下来的输入，因此当解码器在产生一个句子的时候，它有可能看到错误的东西。如果解码器有 语音识别的错误，它把机器的“器”识别错成天气的“气”，接下来解码器会根据错误的识别结果 产生它想要产生的期待是正确的输出，这会造成误差传播（error propagation）的问题，一步 错导致步步错，接下来可能无法再产生正确的词汇。**这个后面再说**

类似于编码器，解码器也有多头 注意力、残差连接和层归一化、前馈神经网络。解码器最后再做一个softmax，使其输出变成 一个概率。此外，解码器使用了**掩蔽自注意力（masked self-attention）**，掩蔽自注意力可以通 过一个掩码（mask）来阻止每个位置选择其后面的输入信息。
![[Pasted image 20251012105311.png]]
原来的自注意力输入一排向量，输出另外一排向量，这一排中每个向量 都要看过完整的输入以后才做决定。根据a1到a4所有的信息去输出b1。掩蔽自注意力的不 同点是==不能再看右边的部分==，如图7.19所示，产生b1 的时候，只能考虑a1 的信息，不能再 考虑a2、a3、a4。产生b2 的时候，只能考虑a1、a2 的信息，不能再考虑a3、a4 的信息。产 生b3 的时候，不能考虑a4 的信息。产生b4 的时候，可以用整个输入序列的信息。

![[Pasted image 20251012105536.png]]
![[Pasted image 20251012105725.png]]

Q: 为什么需要在注意力中加掩码? 
A: 一开始解码器的输出是一个一个产生的，所以是先有a1 再有a2，再有 a3，再有 a4。这跟原来的自注意力不一样，原来的自注意力a1 跟a4 是一次整个输进去模型里 面的。编码器是一次把a1 跟a4 都整个都读进去。但是对解码器而言，先有a1 才有 a2，才有a3 才有a4。所以实际上当我们有a2，要计算b2 的时候，没有a3 跟a4 的， 所以无法考虑a3 a4。解码器的输出是一个一个产生的，所以只能考虑其左边的东西， 没有办法考虑其右边的东西

了解了解码器的运作方式，但这还有一个非常关键的问题：实际应用中输入跟输出长度 的关系是非常复杂的，我们无法从输入序列的长度知道输出序列的长度，因此解码器必须决 定输出的序列的长度。给定一个输入序列，机器可以自己学到输出序列的长度。但在目前的解 码器运作的机制里面，机器不知道什么时候应该停下来，如图7.22所示，机器产生完“习”以 后，还可以继续重复一模一样的过程，
![[Pasted image 20251012110134.png]]
如图7.23 所示，要让解码器停止运作，需要特别准备一个特别的符号。产生完 “习”以后，再把“习”当作解码器的输入以后，解码器就要能够输出`<EOS>`，解码器看到编码 器输出的嵌入、、“机”、“器”、“学”、“习”以后，其产生出来的向量里面 的概率 必须是最大的，于是输出，整个解码器产生序列的过程就结束了.

##### 7.4.2非自回归解码器
假设产生 是中文的句子，非自回归不是一次产生一个字，它是一次把整个句子都产生出来。非自回归的 解码器可能“吃”的是一整排的词元，一次产生产生一排词元。比如输入4个 的词元到非自回归的解码器，它就产生4个中文的字。因为输出的长度是未知的，所以当做 非自回归解码器输入的的数量也是未知的，因此有如下两个做法。
- 用分类器来解决这个问题。用分类器“吃”编码器的输入，输出是一个数字，该数字代表 解码器应该要输出的长度。比如分类器输出4，非自回归的解码器就会“吃”4个 的词元，产生4个中文的字。
- 给编码器一堆`<BOS> `的词元。假设输出的句子的长度有上限，绝对不会超过 300 个 字。给编码器300个，就会输出300个字，输出右边的的输出就当它没有输出.
	非自回归的解码器有很多优点。第一个优点是平行化。自回归的解码器输出句子的时候 是一个一个字产生的，假设要输出长度一百个字的句子，就需要做一百次的解码。但是非自回 归的解码器不管句子的长度如何，都是一个步骤就产生出完整的句子。所以非自回归的解码器 会跑得比自回归的解码器要快。非自回归解码器的想法是在有Transformer以后，有这种自注 意力的解码器以后才有的。以前如果用长短期记忆网络（Long Short-Term Memory Network， LSTM）或 RNN，给它一排，其无法同时产生全部的输出，其输出是一个一个产生 的。
	另外一个优点是非自回归的解码器比较能够控制它输出的长度。在语音合成里面，非自 回归解码器算是非常常用的。非自回归的解码器可以控制输出的长度，可以用一个分类器决 定非自回归的解码器应该输出的长度。在做语音合成的时候，如果想要让系统讲快一点，就把 分类器的输出除以2，系统讲话速度就变2倍快。

平行化是非自回归解码器最大的优势，但非自回归的解码器的性能（performance）往往 都不如自回归的解码器。所以很多研究试图让非自回归的解码器的性能越来越好，去逼近自 回归的解码器。要让非自回归的解码器跟自回归的解码器性能一样好，必须要使用非常多的 技巧.
#### 7.5编码器-解码器注意力
编码器和解码器通过编码器-解码器注意力（encoder-decoder attention）传递信息，编码 器-解码器注意力是连接编码器跟解码器之间的桥梁。
解码器中编码器-解码器注意力的键(K)和值(V)来自编码器的输出，查询(Q)来自解码器中前一个层的输出。
![[Pasted image 20251012111234.png]]
接下来介绍下编码器-解码器注意力实际的运作过程。如图7.26所示，编码器输入一排向 量，输出一排向量a1、a2、a3。接下来解码器会先“吃”，经过掩蔽自注意力得到一个 向量。接下来把这个向量乘上一个矩阵，做一个变换（transform），得到一个查询q，a1、a2、 a3 也都产生键：k1、k2、k3。把 q 跟k1、k2、k3 去计算注意力的分数，得到α1、α2、α3， 接下来做softmax，得到 α′ 1、α′ 2、α′ 3。接下来通过式(7.2) 可得加权和 v。
如图7.27 所示，假设产生“机”，输入、“机”，产生一个向量。这个向量一样乘上 一个线性变换得到一个查询q′。q′ 会跟k1、k2、k3 计算注意力的分数。接着用注意力分数 跟v1、v2、v3 做加权和，加起来得到v′，最后交给全连接网络处理。
![[Pasted image 20251012111500.png]]
这个编码器解码器注意力叫做 Cross attention
编码器和解码器都有很多层，但在原始论文中解码器是拿编码器最后一层的输出。但不 一定要这样
#### 7.6 Transformer 的训练过程
如图7.28 所示，Transformer 应该要学到听到“机器学习”的声音信号，它的输出就是“机 器学习”这四个中文字。把丢给编码器的时候，其第一个输出应该要跟“机”越接近越好.
而解码器的输出是一个概率的分布,这个概率分布跟“机”的独热向量越接近越好。因此我 们会去计算标准答案（Ground Truth）跟分布之间的交叉熵，希望该交叉熵的值越小越好。 每一次解码器在产生一个中文字的时候做了一次类似分类的问题。
![[Pasted image 20251012112534.png]]
在训练的时候，每一个输出跟其对应的正确答 案都有一个交叉熵。图7.29中做了四次分类问题，希望这些分类的问题交叉熵总和越小越好。训练的时候，解码器输出的不是只有“机器学习”这四个中文字，还要输出`<EOS>`。所以解码 器的最终第五个位置输出的向量跟的独热向量的交叉熵越小越好。
我们==把标准答案给解码器==，希望解码器的输出跟正确答案越接近越好。在训练的时候，告诉解码器在已经有 、“机”的情况下，要输出“器”，有 、“机”、“器”的情况下输出“学”，有 、“机”、“器”、“学”的情况下输出“习”，有 、“机”、“器”、“学”、“习”的情况下，输出 。 在解码器训练的时候，在输入的时候给它正确的答案，这称为教师强制（teacher forcing）。
#### 7.7 序列到序列模型训练常用技巧 
接下来介绍下训练序列到序列模型的一些技巧。
##### 7.7.1复制机制
**对很多任务而言，解码器没有必要自己创造 输出，其可以从输入的东西里面复制一些东西。** 以聊天机器人为例，用户对机器说：“你好，我 是库洛洛”。机器应该回答：“库洛洛你好，很高兴认识你”。机器其实没有必要创造“库洛洛”这 个词汇，“库洛洛”对机器来说一定会是一个非常怪异的词汇，所以它可能很难在训练数据里面 出现，可能一次也没有出现过，所以它不太可能正确地产生输出。但是假设机器在学的时候， 学到的并不是它要产生“库洛洛”，它学到的是看到输入的时候说“我是某某某”，就直接把“某某 某”复制出来，说“某某某你好”。这种机器的训练会比较容易，显然比较有可能得到正确的结 果，所以复制对于对话任务可能是一个需要的技术。
最早有从输入复制东西的能力的模型叫做指针网络（pointer network），后来还有 一个变形叫做复制网络（copy network）
##### 7.7.2 引导注意力
序列到序列模型有时候训练出来会产生莫名其妙的结果。以语音合成为例，机器念4次 的“发财”，重复4次没问题，但叫它只念一次“发财”，它把“发”省略掉只念“财”。也许在训练数 据里面，这种非常短的句子很少，所以机器无法处理这种非常短的句子。
引导 注意力要求机器在做注意力的时候有固定的方式。对语音合成或语音识别，我们想像中的注 意力应该就是由左向右。
![[Pasted image 20251012113925.png]]
如图7.30所示，红色的曲线来代表注意力的分数，越高就代表注意 力的值越大。以语音合成为例，输入就是一串文字，合成声音的时候，显然是由左念到右。所 以机器应该是先看最左边输入的词汇产生声音，再看中间的词汇产生声音，再看右边的词汇 产生声音。如果做语音合成的时候，机器的注意力是颠三倒四的，它先看最后面，接下来再看 前面，再胡乱看整个句子，显然这样的注意力是有问题的，没有办法合出好的结果。因此引导 注意力会强迫注意力有一个固定的样貌，如果我们对这个问题本身就已经有理解，知道对于 语音合成这样的问题，注意力的位置都应该由左向右，不如就直接把这个限制放进训练里面， 要求机器学到注意力就应该要由左向右。
monotonic attention, location-aware attention
##### 7.7.3 束搜索
如图7.31 所示，假设解码器就只能产生两个字A和B，假如世界上只有两个字A跟B， 即词表V={A,B}。对解码器而言，每一次在第一个时间步（timestep），它在A、B里面决 定一个。比如解码器可能选B当作输入，再从A、B中选一个。在上文中，每一次解码器都 是选分数最高的那一个。假设A的分数是0.6，B的分数是0.4，解码器的第一次就会输出A。 接下来假设B的分数为0.6，A的分数为0.4，解码器就会输出B。再假设把B当做输入，现在输入已经有A、B，接下来A的分数是0.4，B的分数是0.6，解码器就会选择输出B。因此 输出就是A、B、B。这种每次找分数最高的词元来当做输出的方法称为贪心搜索（greedy search），其也被称为贪心解码（greedy decoding）。红色路径就是通过贪心解码得到的路 径。
![[Pasted image 20251012114208.png]]
但贪心搜索不一定是最好的方法，第一步可以先稍微舍弃一点东西，第一步虽然B是0.4， 但先选B。选了B，第二步时B的可能性就大增就变成0.9。到第三步时，B的可能性也是 0.9。绿色路径虽然第一步选了一个较差的输出，但是接下来的结果是好的。比较下红色路径 与绿色路径，红色路径第一步好，但全部乘起来是比较差的，绿色路径一开始比较差，但最终 结果其实是比较好的。
如何找到最好的结果是一个值得考虑的问题。穷举搜索（exhaustive search）是最容易想 到的方法，但实际上并没有办法穷举所有可能的路径，因为每一个转折点的选择太多了。对中 文而言，中文有4000 个字，所以树每一个地方的分叉都是4000个可能的路径，走两三步以 后，就会无法穷举。
接下来介绍下**束搜索（beam search）**，束搜索经常也称为集束搜索或柱搜索。束搜索 是用比较有效的方法找一个近似解，在某些情况下效果不好。比如论文“The Curious Case Of Neural Text Degeneration”[5]。这个任务要做的事情是完成句子（sentence completion），也就 是机器先读一段句子，接下来它要把这个句子的后半段完成，如果用束搜索，会发现说机器不 断讲重复的话。如果不用束搜索，加一些随机性，虽然结果不一定完全好，但是看起来至少是 比较正常的句子。有时候对解码器来说，没有找出分数最高的路，反而结果是比较好的，这个就是要看任务本身的特性。假设任务的答案非常明确，比如语音识别，说一句话，识别的结果 就只有一个可能。对这种任务而言，通常束搜索就会比较有帮助。但如果任务需要机器发挥一 点创造力，束搜索比较没有帮助。
##### 7.7.4加入噪声
在做语音合成的时候，解码器加噪声，这是完全违背正常的机器学习的做法。在训练的时 候会加噪声，让机器看过更多不同的可能性，这会让模型比较鲁棒，比较能够对抗它在测试 的时候没有看过的状况。但在测试的时候居然还要加一些噪声，这不是把测试的状况弄得更 困难，结果更差？但语音合成神奇的地方是，模型训练好以后。测试的时候要加入一些噪声， 合出来的声音才会好。用正常的解码的方法产生出来的声音听不太出来是人声，产生出比较 好的声音是需要一些随机性的。对于语音合成或句子完成任务，解码器找出最好的结果不一 定是人类觉得最好的结果，反而是奇怪的结果，加入一些随机性的结果反而会是比较好的。
##### 7.7.5使用强化学习训练
训练的时候，每一个词汇是分开考虑的，最小化的 是交叉熵，最小化交叉熵不一定可以最大化BLEU分数。但在做验证的时候，并不是挑交叉 熵最低的模型，而是挑BLEU分数最高的模型。一种可能的想法：训练的损失设置成BLEU 分数乘一个负号，最小化损失等价于最大化BLEU分数。但BLEU分数很复杂，如果要计算 两个句子之间的BLEU分数，损失根本无法做微分。我们之所以采用交叉熵，而且是每一个 中文的字分开来算，就是因为这样才有办法处理。遇到优化无法解决的问题，可以用强化学习 训练。具体来讲，遇到无法优化的损失函数，把损失函数当成强化学习的奖励，把解码器当成 智能体

##### 7.7.6计划采样
测试的时候，解码器看到的是自己的输出，因此它会看到一些错误的东西。 但是在训练的时候，解码器看到的是完全正确的，这种不一致的现象叫做曝光偏差（exposure bias）。
假设解码器在训练的时候永远只看过正确的东西，在测试的时候，只要有一个错，就会一 步错步步错。因为解码器从来没有看过错的东西，它看到错的东西会非常的惊奇，接下来它 产生的结果可能都会错掉。有一个可以的思考的方向是：给解码器的输入加一些错误的东西， 不要给解码器都是正确的答案，偶尔给它一些错的东西，它反而会学得更好，这一技巧称为计划采样（scheduled sampling）[6]，它不是**学习率调整（schedule learning rate）**。
很早就有 计划采样，在还没有Transformer、只有 LSTM的时候，就已经有计划采样。但是计划采样会 伤害到Transformer 的平行化的能力，所以 Transformer 的计划采样另有招数，其跟原来最 早提在这个LSTM 上被提出来的招数也不太一样。




