在讲自编码器（autoencoder）之前，其实自编码器也可以算是自监督学习的一环
在有BERT 或者GPT模型之前，其实有一个更古老的，不需要用标注数据的任务，就 叫做自编码器，所以你也可以把自编码器看作是一种自监督学习的预训练方法。
## 11.1 自编码器的原理
自编码器的原理，以图像为例，如图11.2所示，假设我们有非常大量的图片，在自编码器 里面有两个网络，一个叫做编码器，另外一个叫做解码器，它们是不同的两个网络。编码器把 一张图片读进来，它把这张图片变成一个向量，编码器可能是很多层的卷积神经网络（CNN）， 把一张图片读进来，它的输出是一个向量，接下来这个向量会变成解码器的输入。而解码器会 产生一张图片，所以解码器的网络架构可能会像是GAN里面的生成器，它是比如11个向量 输出一张图片。
训练的目标是希望编码器的输入跟解码器的输出越接近越好。换句话说，假设你把图片 看作是一个很长的向量的话，我们就希望这个向量跟解码的输出，这个向量，这两个向量他们的距离越接近越好，也有人把这件事情叫做重构（reconstruction）。
![[Pasted image 20251015215813.png]]
因为我们就是把一张 图片，压缩成一个向量，接下来解码器要根据这个向量，重建出原来的图片，希望原输入的结 果跟重建后的结果越接近越好。讲到这里读者可能会发现说，这个概念其实跟前面讲的Cycle GAN 模型是类似的。
在做Cycle GAN 的时候，我们会需要两个生成器，第一个生成器把X域的图片转到Y 域，另外一个生成器把Y域的图片转回来，然后希望最原先的图片跟转完两次后的图片越接 近越好。那这边编码器和解码器，也就是这个自编码器的概念，跟CycleGAN其实是一模一 样的，都是希望所有的图片经过两次转换以后，要跟原来的输出越接近越好，而这个训练的过 程，完全不需要任何的标注数据，你只需要收集到大量的图片，你就可以做这个训练。

怎么把训练好的自编码器用在下游的任务里面呢？常见的用法就是把原来的图片可以看 成是一个很长的向量，但这个向量太长了不好处理，这是把这个图片丢到编码器以后，输出 另外一个向量，这个向量我们会让它比较短，比如说只有10维或者100维。接着拿这个新的 向量来做接下来的任务，也就是图片不再是一个很高维度的向量，它通过编码器的压缩以后， 变成了一个低维度的向量，我们再拿这个低维度的向量，来做接下来想做的事情，这就是自编 码器用在下游任务的常见做法。
由于通常编码器的输入是一个维度非常高的向量，而其输出也就是我们的嵌入（也称为 表示或编码），其是一个非常低维度的向量。本来输入是很宽的，输出也是很 宽的，但是中间特别窄，因此这一段就叫做瓶颈。而编码器做的事情，是把本来很高维度的东 西，转成低维度的东西，把高维度的东西转成低维度的东西又叫做降维。
## 11.2 为什么需要自编码器
自编码器到底好在哪里？当我们把一个高维度的图片，变成一个低维度的向量的时候，到 底带来什么样的帮助呢？我们来设想一下，自编码器这件事情它要做的，是把一张图片压缩 又还原回来，但是还原这件事情为什么能成功呢？能够做到这件事情是因为，对于图像来说，并不是所有3×3的矩阵都是图片，**图片的变 化其实是有限的**，你随便采样一个随机的噪声，随便采样一个矩阵出来，它通常都不是你会 看到的图片。

而编码器做的事情就是化繁为简，有时本来比较复杂的东西，它实际上只是表面上看起 来复杂，而本身的变化是有限的。我们只需要找出其中有限的变化，就可以将它本来比较复杂 的东西用更简单的方法来表示。如果我们可以把复杂的图片，用比较简单的方法来表示它，那 我们就只需要比较少的训练数据，在下游的任务里面，我们可能就只需要比较少的训练数据， 就可以让机器学到，这就是自编码器的概念。

## 11.3 去噪自编码器
自编码器有一个常见的变体，叫做去噪自编码器（denoising autoencoder）。如图11.4 所示，去噪自编码器就是把原来需要输入到编码器的图片，加上一些噪声，然后一样地通过编 码器，再通过解码器，试图还原原来的图片。
我们现在还原的，不是编码器的输入，编码器的输入的图片是有加噪声的，我们要还原的 是加入噪声之前的结果。所以我们会发现现在编码器跟解码器，除了还原原来的图片这个任 务以外，它还多了一个任务，这个任务就是它必须要自己学会把噪声去掉。

其实去噪自编码器也不算是太新的技术，至少在2008年的时候，就已经有相关的论文了。 如果读者看 BERT 模型的话，其实也可以把它看成一个去噪自编码器。输入我们会加掩码， 掩码其实就是噪声，BERT的模型就是编码器，它的输出就是嵌入。接下来有一个线性的模型，就是解码器，解码器要做的事 情，就是还原原来的句子，也就是把填空题被盖住的地方，把它还原回来，所以我们可以说， BERT 其实就是一个去噪的自编码器。有读者可能会问，为什么这个解码器一定要是线性的 呢，其实它不一定要是线性模型。或者换一个说法，如图11.5所示，这个BERT它有12层， 最小的那个BERT有12层，比较大的有24层或者是48层，那最小的BERT是12层，如 果我们说这个12层中间，第6层的输出是嵌入，那其实也可以说剩下的6层，就是解码器。

## 11.4 自编码器应用之特征解耦
自编码器可应用于在特征解耦（feature disentanglement）。解耦是指把一堆本来纠缠 在一起的东西把它解开。
为什么需要解耦？我们先看一下自编码器做的事情.如果是图片的话，就是把一张图片变成一个编码，再把编码变回图片，既然这个编码可以变回图片，代表说**这个编码里面有很多的信息**，包含图片里面所有的信息。举例来说，图片里面 的色泽、纹理等等。不只是图片，还可以应用到语音，文章等地方。这些通过编码器输出的编码都是有很多信息的， 但是这些信息是全部纠缠在一个向量里面，我们并不知道一个向量的哪些维度代表 了哪些信息。
而特征解耦想要做到的事情就是，我们有没有可能想办法，在训练一个自编码器的时候， 同时有办法知道嵌入（又称为表征或编码）的哪些维度代表了哪些信息。
*还可以深入了解怎么做到的*
再举一个特征解耦方面的应用，叫做语音转换。
![[Pasted image 20251015223244.png]]
有了特征解耦的技术以后，我们可以期待机器做到，给它A的声音和B的声音，A跟B 不需要念同样的句子，甚至不需要讲同样的语言，机器也有可能学会把A的声音转成B的声 音。
假设收集到一大堆人类的声音信号，使用这堆声音信号训练 一个自编码器，同时又做了特征解耦，所以我们就知道了在编码器的输出里面，哪些维度代表 了语音的内容，哪些维度代表了讲述者的特征，这样就可以把两句话的声音跟内容的部分互 换

## 11.5 自编码器应用之离散隐表征
自编码器还可以用于离散隐表征。目前为止我们都假设嵌入是一个向量，这样就是一串 实数，那它可不可以是别的东西呢？如图11.11所示，它可以是二进制，好处就是每一个维度 就代表了某种特征的有无。
如果强迫嵌入是独热向量，也就是每一个东西图片丢进去，嵌入里面只可以有一维是1， 其他都是0，也许可以做到**无监督的分类。**  比如我们想要做手写数字识别任务，有0到9的 图片，把这些图片统统收集起来训练一个自编码器，强迫中间的隐表征，也就是中间的这个编 码一定要是独热向量。这个编码正好设个10维，这10维就有10种可能的独热的编码，也许 每一种正好就对应到一个数字。因此如果用独热向量来当做嵌入，也许就可以做到完全在没 有标注数据的情况下让机器自动学会分类。

其实这种离散的表征技术中，最知名的就是**向量量化变分自编码器（vector quantized variational autoencoder）。** 它运作的原理就是输入一张图片，然后编码器输出一个向量， 这个向量它是一般的向量，并且是连续的，但接下来有一个码本，所谓码本的意思就是一排向量，如图11.12 所示。这排向量也是学出来的，把编码器的输出，去跟这排向量计算一个相似 度，然后就会发现这其实跟自注意力有点像，上面这个向量就是查询，下面这些向量就是键， 那接下来就看这些向量里面，谁的相似度最大，把相似度最大的那个向量拿出来，让这个键跟 那个值共用同一个向量。
![[Pasted image 20251015223530.png]]

## 11.6自编码器的其他应用
自编码器其实还可以做更多的应用，前面主要都在讲编码器，其实解码器也有一定的作 用。首先是应用在生成器上，如图11.15所示，把解码器拿出来就相当于一个生成器。而生成 器就是要输入一个向量，然后输出一个东西，比如说一张图片，而解码器的原理也是类似的， 因此解码器也可以当做一个生成器来用。
我们可以从一个已知的分布比如高斯分布中采样一 个向量喂给解码器，然后看看它能不能输出一张图。实际上在前面讲到生成模型的时候有提 到除了GAN以外的另外两种生成模型，其中一个就叫做**变分自编码器（variational auto encoder**）。顾名思义显然可以看出它其实跟自编码器有很大的关系，实际上它就是把自编码 器中的解码器拿出来当做生成器来用，那实际上它还有做一些其他的事情，就留给读者们自 行研究，只是在自编码器训完之后就顺便得到了一个解码器而已。
自编码器还可以用来做压缩.，我们完全可以把编 码器的输出当做是一个压缩的结果。因为一张图片其实是一个非常高维的向量，而一般我们 编码器的输出是一个非常低维的向量，此时完全可以把这个向量看作是一个压缩的结果。只是这个压缩是有损压缩
异常检测？
**由作业，可拓展异常检测 pt1-7**

