Q：什么是通道？ A：彩色图像的每个像素都可以描述为红色（red）、绿色（green）、蓝色（blue）的组 合，这3种颜色就称为图像的3个色彩通道。这种颜色描述方式称为RGB色彩模型， 常用于在屏幕上显示颜色

神经元、感受野、参数共享：同一组权重被不同位置复用
卷积核、滤波器：同一个 kernel 滑动扫描
### 为什么能“拿掉”全连接的大部分参数？

- 影像特性 1：有意义的 pattern 远比整张图小 → **只需局部连接**（Receptive Field）
    
- 影像特性 2：同一 pattern 会出现在不同位置 → **权重共享**（共享 kernel）
    
- 影像特性 3：像素下采样后语义几乎不变 → **Pooling 降维**


**CNN ≠ 神秘黑盒，它只是“被剪掉”的 DNN**
重复同样 的操作，直到把整张图像都扫完，就得到另外一组数值。每个滤波器都会给我们一组数字，红 色的滤波器给我们一组数字，蓝色的滤波器给我们另外一组数字。如果有64个滤波器，就可 以得到64 组的数字。这组数字称为特征映射（feature map）。当一张图像通过一个卷积层 里面一堆滤波器的时候，就会产生一个特征映射。假设卷积层里面有64个滤波器，产生的特 征映射就有64组数字。在上述例子中每一组是4×4，即第1个滤波器产生4×4个数字，第 2 个滤波器也产生4×4个数字，第3个也产生4×4个数字，64个滤波器都产生4×4个 数字。特征映射可以看成是另外一张新的图像，只是这个图像的通道不是RGB 3个通道，有 64 个通道，每个通道就对应到一个滤波器。

卷积层是可以叠很多层的，如图4.22所示，第2层的卷积里面也有一堆的滤波器，每个 滤波器的大小设成3×3。其高度必须设为64，因为滤波器的高度就是它要处理的图像的通道。如果输入的图像是黑白的，通道是1，滤波器的高度就是1。如果输入的图像是彩色的， 通道为3，滤波器的高度就是3。对于第2个卷积层，它的输入也是一张图像，这个图像的通 道是64。这个64 是前一个卷积层的滤波器数目，前一个卷积层的滤波器数目是64，输出以 后就是64 个通道。所以如果第2层想要把这个图像当做输入，滤波器的高度必须是64。所 以第2层也有一组滤波器，只是这组滤波器的高度是64

Q：如果滤波器的大小一直设3×3，会不会让网络没有办法看比较大范围的模式呢？ A：不会。如图4.23 所示，如果在第2层卷积层滤波器的大小一样设3×3，当我们看 第1个卷积层输出的特征映射的3×3的范围的时候，在原来的图像上是考虑了一个 5 ×5 的范围。虽然滤波器只有3×3，但它在图像上考虑的范围是比较大的是5×5。 因此网络叠得越深，同样是3×3的大小的滤波器，它看的范围就会越来越大。所以网 络够深，不用怕检测不到比较大的模式
![[Pasted image 20251011192747.png]]

刚才讲了两个版本的故事，这两个版本的故事是一模一样的。
在第1个版本的故事里面，不同的神经元可以共享权重，去守备不同的 范围。而共享权重其实就是用**滤波器扫过一张图像，这个过程就是卷积**。这就是卷积层名字的 由来。把滤波器扫过图像就相当于不同的感受野神经元可以共用参数，这组共用的参数就叫 做一个滤波器

#### 4.6观察三:下采样不影响模式检测
把一张比较大的图像做下采样（down-sampling）， 把图像偶数的列都拿掉，奇数的行都拿掉，图像变成为原来的1/4，但是不会影响里面是什么 东西
#### 4.7 简化3：汇聚(pooling)

汇聚比较像Sigmoid、ReLU等激活函数。因为它里面是没 有要学习的参数的，它就是一个操作符（operator），其行为都是固定好的，不需要根据数据 学任何东西。

以最大汇聚（max pooling）为例。最大汇聚在每一组里面选一个代表， 选的代表就是最大的一个，如图4.28所示。除了最大汇聚，还有平均汇聚（meanpooling）， 平均汇聚是取每一组的平均值


做完卷积以后，往往后面还会搭配汇聚。汇聚就是把图像变小。做完卷积以后会得到一 张图像，这张图像里面有很多的通道。做完汇聚以后，这张图像的通道不变。

一般架构就是卷积加汇聚，**汇聚是可有可无的**，很多人可能会选择不用汇聚。如图4.30 所示，如果做完几次卷积和汇聚以后，把汇聚的输出做扁平化（flatten，矩阵拉直变成向量），再把这个向量丢进 全连接层里面，最终还要过个softmax 来得到图像识别的结果。这就是一个经典的图像识别 的网络，里面有卷积、汇聚和扁平化，最后再通过几个全连接层或softmax 来得到图像识别 的结果

#### 4.8卷积神经网络应用:下围棋
在做图像的时候都会做汇聚，一张图像做下采样以后，并不会影响我们对图像中物体的 判断。但汇聚对于下围棋这种精细的任务并不实用，下围棋时随便拿掉一个列拿掉一个行，整 个棋局就不一样。AlphaGo 在 Nature 上的论文正文里面没有提它用的网络架构，而是在附 件中介绍了这个细节。

如果想把卷积神经网络用在语音和文字 处理上，就要对感受野和参数共享进行重新设计，其跟图像不同，要考虑语音跟文字的特性来 设计。所以不要以为在图像上的卷积神经网络，直接套到语音上它也奏效（work），可能是不 奏效的。要想清楚图像语音有什么样的特性，要怎么设计合适的感受野


其实卷积神经网络不能处理图像放大缩小或者是旋转的问题
虽然两张图像 的形状是一模一样的，但是如果把它们“拉直”成向量，里面的数值就是不一样的。虽然人眼一 看觉得两张图像的形状很像，但对卷积神经网络来说它们是非常不一样的。
卷积神经网络并没有想像的那么强。因此在做图像识别的时候往往都要做数据增 强。所谓数据增强就是把训练数据每张图像里面截一小块出来放大，让卷积神经网络看过不 同大小的模式；把图像旋转，让它看过某一个物体旋转以后长什么样子，卷积神经网络才会做 到好的结果。卷积神经网络不能够处理缩放（scaling）跟旋转（rotation）的问题，但Spatial Transformer Layer 网络架构可以处理这个问题