#### 6.1输入是向量序列的情况
在图像识别的时候，假设输入的图像大小都是一样的。但如果问题变得复杂，如图6.2所 示，输入是一组向量，并且输入的向量的数量是会改变的，即每次模型输入的序列长度都不一 样，这个时候应该要怎么处理呢？我们通过具体的例子来讲解处理方法。

第一个例子是文字处理，假设网络的输入是一个句子，每一个句子的长度都不一样（每个 句子里面词汇的数量都不一样）。如果把一个句子里面的每一个词汇都描述成一个向量，用向 量来表示，模型的输入就是一个向量序列，而且该向量序列的大小每次都不一样（句子的长度 不一样，向量序列的大小就不一样）。 将词汇表示成向量最简单的做法是独热编码，创建一个很长的向量，该向量的长度跟世 界上存在的词汇的数量是一样多的。假设英文是十万个词汇，创建一个十万维的向量，每一 个维度对应到一个词汇，如式(6.1)所示。但是这种表示方法有一个非常严重的问题，它假设 所有的词汇彼此之间都是没有关系的。。cat 和 dog 都是动物，它们应该比较像；cat 是动物， apple 是植物，它们应该比较不像。**但从独热向量中不能看到这件事情，其里面没有任何语义 的信息。**
除了独热编码，词嵌入（word embedding）也可将词汇表示成向量。词嵌入使用一个 向量来表示一个词汇，而这个向量是包含语义信息的。如图6.3所示，如果把词嵌入画出来， 所有的动物可能聚集成一团，所有的植物可能聚集成一团

声音例子:我们会把一段声音信号取一个范围，这个范围叫做一个窗口（window），把该窗口 里面的信息描述成一个向量，这个向量称为一帧（frame）

一个图（graph）也是一堆向量。社交网络是一个图，在社交网络上面每一个节点就是一个人。每一个节点可以看作是一个向量。每一个人的简介里面的信息（性别、年龄、工作等等） 都可以用一个向量来表示。所以一个社交网络可以看做是一堆的向量所组成的。
##### 6.1.1类型1:输入与输出数量相同(课程只讲)
==输出有三种可能性==
1. 第一种可能性是每一个向量都有一个对应的标签。
么样的应用会用到第一种类型的输出呢？举个例子，如图6.7所示，在文字处理上，假 设我们要做的是词性标注
##### 6.1.2 类型2：输入是一个序列，输出是一个标签
举例而言，如图6.9 所示，输入是文字，比如情感分析。情感分析就是给机器看一段话， 模型要决定说这段话是积极的（positive）还是消极的（negative）。
##### 类型 3：序列到序列
我们不知道应该输出多少个标签，机器要自己决定输出多少个 标签。
翻译就是序列到序列的任务，因为输入输出是不同的语言， 它们的词汇的数量本来就不会一样多。真正的语音识别输入一句话，输出一段文字，其实也是 一个序列到序列的任务

#### 6.2自注意力的运作原理
我们就先只讲第一个类型：输入跟输出数量一样多的状况，以序列标注（sequence labeling） 为例

要怎么解决序列标注的问题呢？直觉的 想法就是使用全连接网络,各个击破，把每一个向量分别输入到全连接网络里面得到输出
!瑕疵:  给机器一个句子：I saw a saw。对于全连接网络，这个句子中的两 个saw 完全一模一样，它们是同一个词汇。既然全连接网络输入同一个词汇，它没有理由输 出不同的东西。但实际上，我们期待第一个saw要输出动词，第二个saw要输出名词。
有没有可能让全连接网络考虑更多的信息，比如上下文的信息呢？这是有可能的，如图6.12所示，把每个向量的前后几个向 量都“串”起来，一起输入到全连接网络就可以了:给全连接网络一整个窗口的信息， 让它可以考虑一些上下文，即与该向量相邻的其他向量的信息

如果是要考虑一整个序列呢？
把窗口开大一点？
但是序列的长度是有长有短的，输入给模型的序列的长度， 每次可能都不一样

如果想要更好地考虑整个输入序列的信息，就要用到**自注意力模型。**

接下来介绍下向量b1 产生的过程
自注意力的目的是考虑整个序列，但是又不希望把整个序列所 有的信息包在一个窗口里面。所以有一个特别的机制，这个机制是根据向量a1找出整个很长 的序列里面哪些部分是重要的，哪些部分跟判断a1是哪一个标签是有关系的。每一个向量跟 a1 的关联的程度可以用数值α(注意力分数)来表示

1 算α：比较常见的做法是用点积（dot product）


![[Pasted image 20251011205208.png]]
把输入的两个向量分别乘上两个不同的矩阵，左边这个向量乘上矩阵Wq，右边这个向量乘上矩 阵Wk，得到两个向量q跟k，再把q跟k做点积，把它们做逐元素（element-wise）的相 乘，再全部加起来以后就得到一个标量（scalar）α，这是一种计算α的方式。
*其实还有其他的计算方式，如图6.18(b) 所示，有另外一个叫做相加（additive）的计算 方式，但是在接下来的内容里面，我们都只用点积这个方法， 这也是目前最常用的方法，也是用在Transformer 里面的方法。*

接下来如何把它套用在自注意力模型里面呢？自注意力模型一般采用查询-键-值（Query Key-Value，QKV）模式，
把 a1 乘上Wq 得到q1。q 称为查询（query），它就像是我们使用搜索引擎查找相关文章所使用的关键字，所以称之为查寻。
接下来要去把a2、a3、a4 乘上Wk 得到向量k，向量k称为键（key）。
#重要
**Q 是“钥匙”，K 是“锁孔”；用钥匙试锁孔（q·k）才能判断哪扇门（token）该被打开，进而拿到门后的宝藏（V）**

2 计算出a1跟每一个向量的关联性以后，接下来会对 所有的关联性做一个softmax 操作，本来有一组α，通过softmax 就得到一组α′
![[Pasted image 20251011205611.png]]
3 把向量a1 到a4 乘上Wv 得到新的向量：v1、v2、v3 和v4，接下来把每一个向量都去 乘上注意力的分数α′，再把它们加起来
![[Pasted image 20251011210000.png]]
如果a1 跟a2 的关联性很强，即α′ 1,2 的值很大。在做加权和（weightedsum）以后，得到的b1 的值就可能会比较接近v2，所以谁的注意力的分数最大，谁的v就会主导（dominant） 抽出来的结果。这边我们讲述了如何从一整个序列得到b1。同理，可以计算出b2到b4。

**注意力分数只是‘权重’，还要乘 W^V（不是 W^Q）再求和，才能把‘权重’变成‘要输出的信息’——否则你只得到一堆 0-1 系数，没拿到任何实际特征。**
线代推导
![[Pasted image 20251011211119.png]]
![[Pasted image 20251011211234.png]]
Q，K转置 得到矩阵A做一些处理可得到A′，A′称为注意力矩阵（attention matrix）。把 A′ 再乘上V 就得到自注意力层的输出O
自注意力的操作较为复杂，但自注意力层里面唯 一==需要学的参数就只有Wq、Wk跟Wv==。只有Wq、Wk、Wv是未知的，需要通过训练数 据把它学习出来的。其他的操作都没有未知的参数，都是人为设定好的，都不需要通过训练数 据学习

#### 6.3多头注意力(头也是超参数)
自注意力有一个进阶的版本——多头自注意力（multi-head self-attention）。
为什么会需要比较 多的头呢？在使用自注意力计算相关性的时候，就是用q去找相关的k。但是相关有很多种 不同的形式，所以也许可以有多个q，不同的q负责不同种类的相关性，这就是多头注意力。
*这边先画qkv再画q1,q2,k1,k2,v1,v2是因为在代码实现中是先乘上一个矩阵，再拆分成两个头，原理等价但少了定义了三个矩阵*
先把 a 乘上一个矩阵得到q，接下来再把q 乘上另外两个矩阵，分别得到 q1、q2。用两个上标，qi,1 跟 qi,2 代表有两个头，i 代表的是位置，1 跟2代表是这个位置的 第几个q，这个问题里面有两种不同的相关性，所以需要产生两种不同的头来找两种不同的相 关性。同理Kv
接下来怎么做自注意力呢，跟之前讲的操作是一模一样的，只是现在1那一 类的一起做，2那一类的一起做。
![[Pasted image 20251011212001.png]]
得到bi,1 跟 bi,2，可能会把 bi,1 跟 bi,2 接起来，再通过一个变换，即再 乘上一个矩阵然后得到bi，再送到下一层去，这就是自注意力的变形——多头自注意力。

#### 6.4位置编码
讲到目前为止，自注意力层少了一个也许很重要的信息，即位置的信息。对一个自注意力 层而言，每一个输入是出现在序列的最前面还是最后面，它是完全没有这个信息的。
对它来说，q1跟q4的距离并没有特别远，1跟4的距离并没有特别 远，2跟3的距离也没有特别近，对它来说就是天涯若比邻，所有的位置之间的距离都是一样 的，没有谁在整个序列的最前面，也没有谁在整个序列的最后面。
但是这可能会有一个问题：位置的信息被忽略了，而有时候位置的信息很重要。举个例子，在做词性标注的时候，我们知 道动词比较不容易出现在句首

因此做自注意力的时候，如果我们觉得位置的信息很重要，需要考虑位置信息时，就要用到位置 编码（positional encoding）
位置编码为每一个位置设定一个向量，位置向量用 ei 来表示，上标 i 代表位置，不同的位置就有不同 的向量，不同的位置都有一个专属的e，把e加到ai上面就结束了

模型在处理输入的时候，它可以知道现在的输入的位置 的信息，这个位置向量是人为设定的。人为设定的向量有很多问题，假设在定这个向量的时候 只定到128，但是序列的长度是129，怎么办呢？在最早的“AttentionIs All You Need” 论文 中，其位置向量是通过正弦函数和余弦函数所产生的，避免了人为设定向量固定长度的尴尬。

#### 6.5截断自注意力
自注意力不是只能用在自然语言处理相关的应用上，它还可 以用在很多其他的问题上。比如在做语音的时候，也可以用自注意力。不过将自注意力用于语 音处理时，可以对自注意力做一些小小的改动。
举个例子，如果要把一段声音信号表示成一组向量，这排向量可能会非常长。非常大的长度会造成什么问题呢？如果L的值很大，计算量就很可观，并且需要很大内存（memory）才能够把该矩阵 存下来。
**截断自注意力（truncated self-attention）** 可以处理向量序列长度过大的问题。截断自注意力在做自注意力的时候不要看一整句话，就只看一个小的范围就好，这个范围是人设定 的。

#### 6.6自注意力与卷积神经网络对比
自注意力还可以被用在图像上。到目前为止，在提到自注意力的时候，自注意力适用的范 围是输入为一组向量的时候。

自注意力跟卷积神经网络之间有什么样的差异或者关联?
可以说 CNN是简化版的自注意(只关注感受野)
，因为在做卷积神经网络的时候，只考虑感受野里面 的信息。而在做自注意力的时候，会考虑整张图像的信息。

在卷积神经网络里面，我们要划定 感受野,大小人划定。VS
自注意力 去找出相关的像素，就好像是感受野是自动被学出来的，网络自己决定感受野的形状

函数集关系:自注意力包括了CNN
既然卷积神经网络是自注意力的一个子集，说明自注意力更灵活。更灵活的模型需要更 多的数据。如果数据不够，就有可能过拟合。、
“An Image is Worth 16 x 16 Words: Transformers for Image Recognition at Scale”:它把每一个图像块就想像成是一个字(nlp)
在这个实验里面，自注意力是浅蓝色的这一条线，卷 积神经网络是深灰色的这条线。随着数据量越来越多，自注意力的结果越来越好。最终在数据 量最多的时候，自注意力可以超过卷积神经网络，但在数据量少的时候，卷积神经网络是可以 比自注意力得到更好的结果的。

Q：自注意力跟卷积神经网络应该选哪一个？ A：事实上可以都用，比如conformer 里面同时用到了自注意力和卷积神经网络。

#### 6.7自注意力与RNN(循环神经网络)对比
我们来比较一下自注意力跟循环神经网络。目前，循环神经网络的角色很大一部分都可 以用自注意力来取代了。
但循环神经网络跟自注意力一样，都是要处理输入是一个序列的状 况。
**循环神经网络中的隐状态存储了历史信息，可以看作一种记忆（Memory）**
在循环神经网络里面有一个输入序列、一个隐状态的向量、一个循环神 经网络的块（block）。循环神经网络的块“吃”记忆的向量，输出一个东西。这个东西会输入全 连接网络来进行预测
接下来当第二个向量作为输入的时候，前一个时间点“吐”出来的东西也会作为输入丢进 循环神经网络里面产生新的向量，再拿去给全连接网络。
![[Pasted image 20251011214852.png]]
自注意力跟循环神经网络有一个显而易见的不同，自注意力的每一个向量都考虑了整个输 入的序列，而循环神经网络的每一个向量只考虑了左边已经输入的向量，它没有考虑右边的向 量。但循环神经网络也可以是双向的，那么每一个隐状态的输出也可以看作是考虑了整个输入的序列。
但是假设把循环神经网络的输出跟自注意力的输出拿来做对比，就算使用双向循环神经 网络还是有一些差别的：
	对于循环神经网络，如果最右边黄色的向量要 考虑最左边的输入，它就必须把最左边的输入存在记忆里面，才能不“忘掉”，一路带到最右 边，才能够在最后一个时间点被考虑。
	但自注意力输出一个查询，输出一个键，只要它们匹配 （match）得起来，“天涯若比邻”。自注意力可以轻易地从整个序列上非常远的向量抽取信息。

自注意力跟循环神经网络还有另外一个更主要的不同是，循环神经网络在处理输入、输 出均为一组序列的时候，是没有办法并行化的。

图也可以看作是一堆向量，但我们不只 有节点的信息，还有边（edge）的信息。如果节点之间是有相连的，图上面的边已经暗示了节点跟节点之间的关联性。所以当 把自注意力用在图上面的时候，我们可以在计算注意力矩阵的时候，只计算有边相连的节点 就好。
如果两个节点之间没有相连，这两 个节点之间就没有关系。既然没有关系，就不需要再去计算它的注意力分数，直接把它设为0 就好了。因为图往往是人为根据某些领域知识（domainknowledge）建出来的，所以从领域知 识可知这两个向量之间没有关联，就没有必要再用机器去学习这件事情。当把自注意力按照 这种限制用在图上面的时候，其实就是一种图神经网络（GraphNeuralNetwork，GNN）



自注意力最早是用在Transformer上面， 所以很多人讲Transformer 的时候，其实指的是自注意力。有人说广义的Transformer指的就 是自注意力，所以后来各种的自注意力的变形都叫做是xxformer，比如Linformer、Performer、 Reformer 等等。这些新的xxformer 往往比原来的Transformer 性能差一点，但是速度会比较 快。