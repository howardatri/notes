自监督学习（Self-Supervised Learning，SSL）是一种无标注的学习方式，YannLeCun 最初在2019 年4月在Facebook（后改名为 Meta）上的一篇帖子上提出了“自监督学习”这个 词。
	监督学习与无监督学习是两种常见的学习方式，如果在模型训练期间使用标注的数据，则 称之为==监督学习==. 如果没有使用标注的数据，则称之为==无监督学习==.
我们需要有标注的文章数据来训练监督模型，而自监督学习是一种无标注的学习方式。他就是把一篇未标注的文章x，分为两部分，一部分输入并产生输出y，让y尽可能接近另一部分。这就是监督学习。
由于自监督学习不使用标注的数据，因此自监督学习可以看作是一种无监督学习方法. 为 什么不直接称其为无监督学习？因为无监督学习是一个比较大的家族，里面有很多不同的方 法，自监督学习只是其中之一. 为了使定义更清晰，称其为自监督学习
命名都是以芝麻街中的成员命名，比如ELMo,BERT,Big Bird
## 10.1 来自transformer 的双向编码器表示(BERT)
BERT 模型是自监督学习的经典模型。BERT是一个Transformer的编码器，架构完全相同。BERT可以输入一行向量，输出同样长度的向量。
BERT 一般用在自然语言处理中，用在文本场景中，所以一般它的输入是一个文本序列， 也是一个数据序列。因为BERT最早是用在文本中，所以这里都以文本为例（语音或图像也都是一样的）
BERT 的输入是一段文字.接下来需要随机掩码一些输入文字，被掩码的部分是随机决定的。
*什么是词元？词元是处理一段文本时的基本单位，词元的单位大小由 我们自己决定. 在中文文本中，通常将一个汉字当成一个词元.*
有两种方法来实现掩码，如图10.3所示. 第一种方法是用特殊符号替换句子中的单词，使 用“MASK”词元来表示特殊符号，可以将其看成一个新的汉字，它不在字典里，它的意思是掩 码原文. 掩码的目的是对向量中某些值进行掩盖，避免无关位置的数值对运算造成影响. 另一 种方法是用另一个字随机替换一个字
		• 添加一个名为“MASK”的特殊词元；
		• 用另一个词替换某个词.
**这就是一个训练猜词填空的网络，但是能干别的**
如何训练BERT模型？如图10.5 所示，我们知道被掩码字符是哪个字符，而BERT不 知道. 因为把句子交给BERT时，该字符被掩码了，所以BERT不知道该字符，但我们知道 掩码字符“深度”一词中的“度”. 因此，训练的目标是输出一个尽可能接近真实答案的字符，即 “度”字符. 独热编码可以用来表示字符，并最小化输出和独热向量之间的交叉熵损失. 这个问 题可以看成一个分类问题，只是类的数量和汉字的数量一样多.在训练过程中，在BERT之后添加一个线性模型并将它们 一起训练. 所以，BERT内部是一个Transformer 的编码器，它有一堆参数. 线性模型是一个 矩阵，它也有一些参数，尽管与BERT相比，其数量要少得多. 我们需要联合训练BERT和 线性模型并尝试预测被掩码的字.
*这个线性变换也是需要学习的部分*
![[Pasted image 20251014221834.png]]
事实上，训练BERT时，除了掩码之外，还有另一种方法：下一句预测（nextsentence prediction）. 我们可以通过在互联网上使用爬虫来获得的大量句子来构建数据库，然后从数 据库中拿出两个句子.这两个句子中间加入了一个特殊的词元`[SEP]`来代表 它们之间的分隔.这样，BERT就可以知道这两个句子是不同的句子，因为这两个句子之间有 一个分隔符号. 我们还将会在整个序列的最前面加入一个特殊词元分类符号`[CLS]`.
![[Pasted image 20251014222733.png]]
现在给定一个很长的序列，其中包括两个句子，中间有个`[SEP]`词元，前面有一个`[CLS]` 词元. 如果将这个很长的序列输入到BERT，它应该输出一个序列。我们只取与`[CLS]`对应的输出，忽略其他输出，并将`[CLS] `的输出乘以线性变换. 现在它做一个二元分类问题，它有两个可能的输出：是或否. 这种方法 是下一句预测，即需要预测第二句是否是第一句的后一句（这两个句子是不是相接的）
但后来的研究发现，下一句预测对BERT将要完成的任务并没有真正的帮助.对于BERT来说，预测两个句子是否相接并不难. 因此，在训练BERT完成下一句 预测任务时，没有学到太多有用的东西.
还有一种类似于下一句预测的方法——句序预测（SentenceOrderPrediction，SOP）,更复杂一点。使用该任务训练的模型叫做ALBERT
### 10.1.1 BERT使用方式
通过猜词填空和句子顺序两个仍无，BERT学会了如何填空。训练完可以干一些与填空无关的、真正使用BERT的任务，可称为**下游任务(downstream task)**，这才是我们实际关心的问题。但当BERT学习完成这些任务时，仍然需要一些标注的数据，也就是监督学习。
![[Pasted image 20251014222754.png]]
给BERT 一些有标注的数据，它可以学习各种任务，将BERT 分化并用于各种任务称 为**微调（fine-tuning）**. 所以微调 BERT，也就是对BERT进行微调，让它可以做某种任务. 与微调相反，在微调之前产生此BERT的过程称为**预训练**. 所以产生BERT的过程就是自监 督学习，也可以将其称为预训练.
如何测试BERT的能力？这里介绍了通用语言理解评估(GLUE)，当然这个还有升级版，就是 super GLUE。

BERT 究竟是如何使用的？接下来介绍下4个使用BERT的情况
#### 情况1：情感分析
假设下游任务是输入一个序列并输出一个类别.这是一个分类问题，只是输入是一个序列. 输入一个序列并输出一个类是一种什么样的任务？例如，情感分析，给机器一个句子，并告诉 它判断句子是正面的还是负面的。对于BERT，它是如何解决情感分析的问题的？如图10.9 所示，只要给它一个句子，把`[CLS]`词元放在这个句子前面.`[CLS]`、w1、w2、w3 4 个输入对 应于4 个输出. 接着，对`[CLS]` 对应的向量应用线性变换，将其乘上一个矩阵. 这里省略了 softmax，通过 softmax 来确定输出类别是正面的或负面的等等. 但是，必须要有下游任务的 标注数据。
![[Pasted image 20251014223408.png]]
BERT没有办法从头开始解决情感分析问题，其仍然需要一些标注数据，需要提供很多句 子以及它们的正面或负面标签来训练BERT模型. 在训练过程中，BERT与这种线性变换放 在一起，称为完整的情感分析模型.
在训练时，线性变换和BERT模型都利用梯度下降来更新 参数. 线性变换的参数是随机初始化的，而BERT初始的参数是从学习了做填空题的BERT 来的.把学会填空的BERT放在这里时，它会获得比随机初始化的 BERT 更好的性能

	*BERT学习填空的训练算是无监督，但是使用BERT的整个过程算是半监督*


#注意cls词元
*为什么bert在某些下游任务只取cls生成的结果？*
	****CLS 是 BERT 为“整句话”专门预留的向量**，训练时已让它的表示**聚合了全局信息**，所以下游任务只要**一句话/一对句子的标签**，直接拿 CLS 最方便、也足够好。**


#### 情况2: 词性标注
第二种情况是输入一个序列，然后输出另一个序列，但输入和输出的长度是一样的.
BERT 是如何处理词性标注任务的？如图10.11所示，只需向BERT输入一个句子即可. 之后，对于这句话中的每个词元，如果是中文，就是每一个字，每个字都有一个对应的向量. 然后把这些向量依次通过线性变换和softmax层.最后，网络预测给定单词所属的类别。接下来和情况1完全一样

**注意这里是对句子的部分进行线性变换，task1只取了cls词元进行线性变换**
#### 情况3: 自然语言推理
在情况3中，模型输入两个句子并输出一个类别
这里的例子都是自然语言处理的例子， 但可以将这些例子更改为其他任务
最常见的一种是自然语言推理（Natural Language Inference，NLI）. 给机器两个输 入语句：前提（premise）和假设（hypothesis）. 机器所做的是判断是否可以从前提中推断出 假设，即前提与假设矛盾或者不矛盾？
![[Pasted image 20251014224306.png]]
BERT 如何解决这个问题？如图 10.13 所示，给定两个句子，这两个句子之间有一个特 殊的分隔词元[SEP]，并把 [CLS] 词元放在最前面的位置. 这个序列是 BERT 的输入，然后 BERT将输出另一个长度与输出长度相同的序列. 但只将[CLS]词元作为线性变换的输入
#### 情况4: 基于提取的问答
第四个情况是问答系统，给机器读一篇文章，问它一个问题，它就会回答一个答案. 但这 里的问题和答案有些限制，假设答案必须出现在文章里面，答案一定是文章中的一个片段，这 是基于提取的问答（extraction-based question answering）在此任务中，输入序列包含 一篇文章和一个问题. 文章和问题都是一个序列

如图10.14 所示，将D 和Q放入问答模型中，希望它输出两个正整数s和e. 根据s和 e 可以直接从文章中截出一段就是答案，文章中第s个单词到第e个单词的片段就是正确答 案. 这是当今使用的一种非常标准的方法.
一样，我们仍然继承预训练的BERT.但是这个任务里我们需要从头训练两个向量：我们使用橙色向量和蓝色向量来表示它们，这两个向量的长度与BERT的输出是相 同的
如何使用这两个向量 呢？
如图10.16(a) 所示，首先计算橙色向量和文档对应的输出向量的内积（innerproduct）. 由于有3个词元代表文章，因此它将输出3个向量.计算这3个向量与橙色向量的内积可以 得到3个值. 然后将它们传递给softmax函数，将得到另外3个值。这种内积与注意力非常相似. 如果把橙色部分可以视为查询，把黄色部分视为键，这就是一种注意力，应该尝试找到得 分最高的位置
如图10.16(b) 所示，蓝色部分代表答案结束的地方. 计算蓝色向量和文章对应的黄色向 量的内积，接着对内积使用softmax函数. 最后，找到最大值.
![[Pasted image 20251014224722.png]]
**橙色内积最大值是开始位置，蓝色内积最大值是结束位置**
请注意，蓝色和橙色向量是随机初始化的，而BERT是由其预训练的权重 初始化的

BERT训练使用数据非常大


上述任务均不包括Seq2Seq模型. 如果想解决Seq2Seq 问题怎么办？BERT只有预训练编 码器，有没有办法预训练Seq2Seq 模型的解码器？如图 10.18 所示，图中有一个编码器和一 个解码器. 输入是一串句子，输出是一串句子. 将它们与中间的交叉注意力（crossattention） 连接起来，然后对编码器的输入做一些扰动来损坏它. 解码器是想要输出的句子，跟损坏它之 前是完全相同的. 编码器看到损坏的结果，然后==解码器要输出还原句子被损坏之前的结果==. 训 练这个模型实际上是预训练一个Seq2Seq模型.

![[Pasted image 20251014231151.png]]
损坏的方法有很多，掩码的方法也有很多，到底哪种方法更好呢？谷歌在题为“Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer”的论文中做了相 关的实验，并提出了预训练模型——转移文本到文本的Transformer（Transfer Text-to-Text Transformer，T5）.

### 10.1.2 BERT有用的原因
为什么BERT有用？最常见的解释是，当输入一串文字时，每个文字都有一个对应的向 量，这个向量称为嵌入.(embedding) 这个向量很特别，因为这个向量代表了输入字的意 思
把这些字对应的向量一起画出来并计算它们之间的距离，意思越相似的字，它们的向量 就越接近.中文会有歧义（一 字多义），很多语言也都有歧义. BERT可以考虑上下文，所以同一个字，例如“果”这个字，它 的上下文不同，它的向量是不会一样的.
举了吃的苹果和苹果电脑的具体数据例子
BERT 在填空的过程中学会了每个字的意思. 也许它真的理解中 文，对它而言，中文的符号不再是没有关系的. 因为它了解中文的意思，所以它可以在接下来 的任务中做得更好.
为什么BERT可以输出代表输入字意思的向量？1960年代的语言学家JohnRupertFirth 提出了一个假设，他说要知道一个词的意思，就要看这个词的“公司（company）”，也就是经常 和它一起出现的词汇，也就是它的上下文. 一个词的意思取决于它的上下文. 以苹果中的“果” 为例，如果它经常与吃、树等一起出现，它可能指的是可以吃的苹果；如果经常与电、专利、 股价等一起出现，可能指的是苹果公司. 因此，可以从上下文中推断出单词的意思.
如图10.24 所示，而 BERT 在学习填空的过程中所做的，也许就是学习从上下文中提取 信息. 训练BERT时，给它w1、w2、w3 和w4，掩码w2，并告诉它预测w2.它如何预测w2？ 它会从上下文中提取信息来预测w2. 所以这个向量就是它的上下文信息的精华，可以用来预 测w2 是什么. 如图10.25 所示，这样的想法在 BERT 之前就已经存在了. 有一种技术是词嵌入，词嵌 入中有一种技术称为连续词袋（Continuous Bag Of Words，CBOW）. 连续词袋模型所 做的与BERT 完全相同，把中间挖空，预测空白处的内容. 连续词袋模型可以给每个词汇一 个向量，代表词汇的意思. 连续词袋模型是一个非常简单的模型，它使用了两个变换.

BERT还可以根据不同的上下文从相同的词汇中产生不同的嵌入，因为它是词嵌入的高级 版本，考虑了上下文. BERT抽取的这些向量或嵌入也称为**语境化的词嵌入（contextualized word embedding）.** 训练在文字上的 BERT 也可以用来对蛋白质、DNA 和音乐进行分类.
BERT 可以学到语义，从嵌入中可以清楚地观察到BERT确实知道每个单词的意思，它 知道哪些词汇意思比较像，哪些单词意思比较不像. 即使给它一个乱七八糟的句子，它仍然可 以很好地对句子进行分类. 所以也许它的能力并不完全来自他看得懂文章这件事，可能还有 其他原因. 例如，BERT可能本质上只是一组比较好的初始化参数，它不一定与语义有关，也 许这组初始参数比较适合训练大型模型，这个问题需要进一步的研究来回答
### 10.1.3 BERT 的变种
BERT 还有很多其他的变种，比如多语言BERT（multi-lingual BERT）
多语言BERT有一个非常神奇的功能，如果用英文问答数据训练它，它会自动学习如何 做中文问答.
有的人可能会说：“多语言BERT在预训练的时候看了104种语言，其中包括中文”. 但是 在预训练期间，多语言BERT的学习目标是做填空题，它只学会了中文填空，接下来教它做 英文问答，它居然自动学会了中文问答. 一个简单的解释是：对于多语言的BERT，不同的语 言的差异不大.
BERT 可以将不同语言中具有相同含义的符号放在一起，并使它们的向量很接近. 但是 在训练多语种BERT的时候，如果给它英文，就可以用英文填空. 如果给它中文，它可以用 中文填空，它不会混合在一起. 如果对它来说，不同语言之间没有区别，怎么可能只用英语标 记来填充英语句子呢？给它一个英文句子，为什么它不会用中文填空？但是它没有这样做，这 意味着它知道语言的信息.
语言信息并没有隐藏很深，把所有的英文单词丢到多语言BERT中，把它们的嵌入平均 起来. 如图10.32 所示，把所有中文的嵌入平均起来，两者相减就是中文和英文之间的差距. 给多语言BERT一个英文句子并得到它的嵌入，把这些嵌入加上蓝色的向量，这就是英文和 中文的差距. 对多语言BERT来说，这些向量就变成了中文的句子. 要求它填空时，它实际上 可以用中文填答案.
![[Pasted image 20251015204537.png]]
多语种BERT可以做一个很棒的无监督翻译

## 10.2 生成式预训练（GPT）
在自监督学习中，除了BERT系列的模型，还有一个非常有名的模型—–GPT系列的模 型. BERT 做的是填空题，而 GPT 就是改一下在自监督学习的时候要模型做的任务. GPT 要做的任务是预测接下来会出现的词元
例如，假设训练数据里面，有一个 句子是“深度学习”. 给GPT输入词元BOS（beginning of sentence），GPT 会输出一个嵌 入（embedding）. 接下来用这个嵌入去预测下一个应该出现的词元. 在这个句子里面，根据 这笔训练数据，下一个应该出现的词元是“深”.

接下来讲下这个部分的具体操作，对一个嵌入h进行一个线性变换，再进行一个softmax 操作可以得到一个分布. 跟一般做分类的问题是一样的，输出的分布跟正确答案的交叉熵（cross entropy）越小越好. 也就是要去预测下一个出现的词元. 接下来要做的事情就是以此类 推了，给GPT输入BOS跟“深”，它产生嵌入. 接下来它会预测下一个出现的词元，告诉 它说下一个应该出现的词元是“度”. 再反复继续下去，给它BOS、“深”和“度”，然后预测下 一个应该出现的词元，它应该要预测“学”. 给GPT输入BOS、“深”“度”和“学”，接下来下 一个应该出现的词元是“习”，因此它应该要预测出下一个应该出现的词元是“习”.
实际上不会只用一笔句子训练GPT，而是用成千上万个句子来训练模型，GPT用了很 多数据训练了一个非常大的模型. GPT模型建立在Transformer 的解码器的基础上，不过其 会做mask 的注意力，给定预测“深”的时候，不会看到接下来出现的词汇
因为GPT可以预测下 一个词元，所以它有生成的能力，可以让它不断地预测下一个词元产生完整的文章，大家提 到GPT的时候，往往会想到独角兽. 因为GPT系列最知名的一个例子，就是用GPT写了 一篇跟独角兽有关的假新闻，假新闻里面说在安第斯山脉发现了独角兽，

GPT 系列可以把一句话补完，如何把一句话补完用在下游的任务上呢？例如，怎么把 GPT 用在问答或者是其他的跟自然语言处理有关的任务上呢？GPT可以跟BERT用一样的 做法，BERT是把Transformer 编码器后面接一个简单的线性的分类器，也可以把GPT拿出 来接一个简单的分类器，这也是会有效的，但是在GPT的论文没有这样做. GPT模型太大 了，大到连微调可能都有困难.
我们希望GPT系列的模型也能够举一反三，可以进行小 样本学习（few-shot learning）
假设要GPT做翻译，如图10.36(a)所示，先输入“把英语翻译成法语（TranslateEnglish to French）”，这个句子代表问题的描述. 然后给它几个范例，接下来输入cheese，让它把后面 的补完，希望它就可以产生翻译的结果. 在训练的时候GPT并没有教它做翻译这件事，它唯 一学到的就是给一段文字的前半段把后半段补完. 现在直接给它前半段的文字就长这个样子， 让它翻译. 给几个例子，告诉模型说翻译是怎么回事，接下来输入单词cheese.GPT中的小样本学习不是一般的学习，这里面完全没有梯度下降， 训练的时候就是要跑梯度下降，而GPT中完全没有梯度下降，完全没有要去调GPT模型参数的意思. 这种训练称为**语境学习（in-context learning）**，代表它不是一种一般的学习，它 连梯度下降都没有做.